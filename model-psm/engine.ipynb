{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip\n",
    "#!pip install --upgrade tensorflow\n",
    "#!pip install --upgrade numpy\n",
    "#!pip install --upgrade nltk\n",
    "#!pip install --upgrade pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'rnnsm' from 'rnnsm.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, re, json, time, shutil\n",
    "import itertools\n",
    "import collections\n",
    "from IPython.display import display\n",
    "\n",
    "# NLTK for NLP utils and corpora\n",
    "import nltk\n",
    "\n",
    "# NumPy and TensorFlow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Pandas because pandas are awesome, and for pretty-printing\n",
    "import pandas as pd\n",
    "# Set pandas floating point display\n",
    "pd.set_option('float_format', lambda f: \"{0:.04f}\".format(f))\n",
    "\n",
    "# Helper libraries for this notebook\n",
    "import utils; reload(utils)\n",
    "import vocabulary; reload(vocabulary)\n",
    "import rnnsm; reload(rnnsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import rnnsm; reload(rnnsm)\n",
    "\n",
    "# Clear old log directory\n",
    "shutil.rmtree(\"tf_summaries\", ignore_errors=True)\n",
    "\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "  tf.set_random_seed(42)\n",
    "\n",
    "  sm = rnnsm.RNNSM(V=10000, H=200, num_layers=2)\n",
    "  sm.BuildCoreGraph()\n",
    "  sm.BuildTrainGraph()\n",
    "  sm.BuildSamplerGraph()\n",
    "\n",
    "  summary_writer = tf.train.SummaryWriter(\"tf_summaries\", \n",
    "                                          tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input words:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_0</th>\n",
       "      <th>w_1</th>\n",
       "      <th>w_2</th>\n",
       "      <th>w_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>Mary</td>\n",
       "      <td>had</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>The</td>\n",
       "      <td>lamb</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   w_0   w_1   w_2  w_3\n",
       "0  <s>  Mary   had    a\n",
       "1  <s>   The  lamb  was"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_0</th>\n",
       "      <th>w_1</th>\n",
       "      <th>w_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>little</td>\n",
       "      <td>lamb</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>white</td>\n",
       "      <td>as</td>\n",
       "      <td>snow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      w_0   w_1   w_2\n",
       "0  little  lamb     .\n",
       "1   white    as  snow"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target words:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_0</th>\n",
       "      <th>y_1</th>\n",
       "      <th>y_2</th>\n",
       "      <th>y_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mary</td>\n",
       "      <td>had</td>\n",
       "      <td>a</td>\n",
       "      <td>little</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The</td>\n",
       "      <td>lamb</td>\n",
       "      <td>was</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_0   y_1  y_2     y_3\n",
       "0  Mary   had    a  little\n",
       "1   The  lamb  was   white"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_0</th>\n",
       "      <th>y_1</th>\n",
       "      <th>y_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lamb</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>as</td>\n",
       "      <td>snow</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_0   y_1  y_2\n",
       "0  lamb     .  <s>\n",
       "1    as  snow    ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "toy_corpus = \"<s> Mary had a little lamb . <s> The lamb was white as snow . <s>\"\n",
    "toy_corpus = np.array(toy_corpus.split())\n",
    "\n",
    "print \"Input words:\"\n",
    "bi = utils.batch_generator(toy_corpus, batch_size=2, max_time=4)\n",
    "for i, (w,y) in enumerate(bi):\n",
    "  utils.pretty_print_matrix(w, cols=[\"w_%d\" % d for d in range(w.shape[1])], dtype=object)\n",
    "\n",
    "print \"Target words:\"\n",
    "bi = utils.batch_generator(toy_corpus, batch_size=2, max_time=4)\n",
    "for i, (w,y) in enumerate(bi):\n",
    "  utils.pretty_print_matrix(y, cols=[\"y_%d\" % d for d in range(w.shape[1])], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_epoch(sm, session, batch_iterator, train=False,\n",
    "              verbose=False, tick_s=10, \n",
    "              keep_prob=1.0, learning_rate=0.1):\n",
    "  start_time = time.time()\n",
    "  tick_time = start_time  # for showing status\n",
    "  total_cost = 0.0  # total cost, summed over all words\n",
    "  total_words = 0\n",
    "\n",
    "  if train:\n",
    "    train_op = sm.train_step_\n",
    "    keep_prob = keep_prob\n",
    "    loss = sm.train_loss_\n",
    "  else:\n",
    "    train_op = tf.no_op()\n",
    "    keep_prob = 1.0  # no dropout at test time\n",
    "    loss = sm.loss_  # true loss, if train_loss is an approximation\n",
    "\n",
    "  for i, (w, y) in enumerate(batch_iterator):\n",
    "    cost = 0.0\n",
    "    #### YOUR CODE HERE ####\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # At first batch in epoch, get a clean intitial state\n",
    "    if i == 0:\n",
    "        h = session.run(sm.initial_h_, {sm.input_w_: w})\n",
    " \n",
    "    cost, h, _ = session.run([loss, sm.final_h_, train_op], feed_dict= {sm.target_y_: y, sm.initial_h_:h,\n",
    "        sm.input_w_: w, sm.dropout_keep_prob_:keep_prob, sm.learning_rate_:learning_rate})      \n",
    "    \n",
    "    #### END(YOUR CODE) ####\n",
    "    total_cost += cost\n",
    "    total_words += w.size  # w.size = batch_size * max_time\n",
    "\n",
    "    ##\n",
    "    # Print average loss-so-far for epoch\n",
    "    # If using train_loss_, this may be an underestimate.\n",
    "    if verbose and (time.time() - tick_time >= tick_s):\n",
    "      avg_cost = total_cost / total_words\n",
    "      avg_wps = total_words / (time.time() - start_time)\n",
    "      print \"[batch %d]: seen %d words at %d wps, loss = %.3f\" % (i,\n",
    "          total_words, avg_wps, avg_cost)\n",
    "      tick_time = time.time()  # reset time ticker\n",
    "\n",
    "  return total_cost / total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "concat() expects at least one object!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-29c363a31e3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#vocab, train_ids, test_ids = utils.load_corpus(\"small.1.txt\", split=0.8, V=V, shuffle=42)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mccc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPlaintextCorpusReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"small.1.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mccc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/nltk/corpus/reader/plaintext.pyc\u001b[0m in \u001b[0;36mparas\u001b[1;34m(self, fileids)\u001b[0m\n\u001b[0;32m    115\u001b[0m         return concat([self.CorpusView(path, self._read_para_block, encoding=enc)\n\u001b[0;32m    116\u001b[0m                        \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                        in self.abspaths(fileids, True, True)])\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_word_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/nltk/corpus/reader/util.pyc\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(docs)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'concat() expects at least one object!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m     \u001b[0mtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: concat() expects at least one object!"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "reload(utils)\n",
    "#V = 2000\n",
    "#vocab, train_ids, test_ids = utils.load_corpus(\"small.1.txt\", split=0.8, V=V, shuffle=42)\n",
    "ccc = nltk.corpus.PlaintextCorpusReader(\"./\", \"small.1.txt\")\n",
    "print ccc.paras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "max_time = 20\n",
    "batch_size = 50\n",
    "learning_rate = 0.5\n",
    "keep_prob = 1.0\n",
    "num_epochs = 5\n",
    "\n",
    "# Model parameters\n",
    "model_params = dict(V=V, \n",
    "                    H=100, \n",
    "                    num_layers=1)\n",
    "\n",
    "trained_filename = 'tf_saved_rnnsm_trained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score_dataset(sm, session, ids, name=\"Data\"):\n",
    "  bi = utils.batch_generator(ids, batch_size=100, max_time=100)\n",
    "  cost = run_epoch(sm, session, bi, \n",
    "                   learning_rate=1.0, keep_prob=1.0, \n",
    "                   train=False, verbose=False, tick_s=3600)\n",
    "  print \"%s: avg. loss: %.03f  (perplexity: %.02f)\" % (name, cost, np.exp(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-44-10c8c0457388>:16 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-44-10c8c0457388>:16 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] Starting epoch 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-10c8c0457388>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m#### YOUR CODE HERE ####\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mrun_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m#### END(YOUR CODE) ####\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-8c4e0c2b3f54>\u001b[0m in \u001b[0;36mrun_epoch\u001b[1;34m(lm, session, batch_iterator, train, verbose, tick_s, keep_prob, learning_rate)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     cost, h, _ = session.run([loss, lm.final_h_, train_op], feed_dict= {lm.target_y_: y, lm.initial_h_:h,\n\u001b[1;32m---> 28\u001b[1;33m         lm.input_w_: w, lm.dropout_keep_prob_:keep_prob, lm.learning_rate_:learning_rate})      \n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m#### END(YOUR CODE) ####\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 766\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 964\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    965\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1014\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1015\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1003\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Will print status every this many seconds\n",
    "print_interval = 5\n",
    "\n",
    "# Clear old log directory\n",
    "shutil.rmtree(\"tf_summaries\", ignore_errors=True)\n",
    "\n",
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "  # Seed RNG for repeatability\n",
    "  tf.set_random_seed(42)\n",
    "  \n",
    "  with tf.variable_scope(\"model\", reuse=None):\n",
    "    sm = rnnsm.RNNSM(**model_params)\n",
    "    sm.BuildCoreGraph()\n",
    "    sm.BuildTrainGraph()\n",
    "  \n",
    "  session.run(tf.initialize_all_variables())\n",
    "  saver = tf.train.Saver()\n",
    "  \n",
    "  for epoch in xrange(1,num_epochs+1):\n",
    "    t0_epoch = time.time()\n",
    "    bi = utils.batch_generator(train_ids, batch_size, max_time)\n",
    "    print \"[epoch %d] Starting epoch %d\" % (epoch, epoch)\n",
    "    #### YOUR CODE HERE ####\n",
    "\n",
    "    run_epoch(sm, session, bi, train=True, keep_prob=keep_prob, learning_rate=learning_rate)\n",
    "\n",
    "    #### END(YOUR CODE) ####\n",
    "    print \"[epoch %d] Completed in %s\" % (epoch, utils.pretty_timedelta(since=t0_epoch))\n",
    "    \n",
    "    ##\n",
    "    # score_dataset will run a forward pass over the entire dataset\n",
    "    # and report perplexity scores. This can be slow (around 1/2 to \n",
    "    # 1/4 as long as a full epoch), so you may want to comment it out\n",
    "    # to speed up training on a slow machine. Be sure to run it at the \n",
    "    # end to evaluate your score.\n",
    "    print (\"[epoch %d]\" % epoch),\n",
    "    score_dataset(sm, session, train_ids, name=\"Train set\")\n",
    "    print (\"[epoch %d]\" % epoch),\n",
    "    score_dataset(sm, session, test_ids, name=\"Test set\")\n",
    "    print \"\"\n",
    "    \n",
    "    # Save a checkpoint\n",
    "    saver.save(session, 'tf_saved_rnnsm', global_step=epoch)\n",
    "    \n",
    "  # Save final model\n",
    "  saver.save(session, trained_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_step(sm, session, input_w, initial_h):\n",
    "  \"\"\"Run a single RNN step and return sampled predictions.\n",
    "  \n",
    "  Args:\n",
    "    sm : rnnsm.RNNSM\n",
    "    session: tf.Session\n",
    "    input_w : [batch_size] list of indices\n",
    "    initial_h : [batch_size, hidden_dims]\n",
    "  \n",
    "  Returns:\n",
    "    final_h : final hidden state, compatible with initial_h\n",
    "    samples : [batch_size, 1] vector of indices\n",
    "  \"\"\"\n",
    "  #### YOUR CODE HERE ####\n",
    "  # Reshape input to column vector\n",
    "  input_w = np.array(input_w, dtype=np.int32).reshape([-1,1])\n",
    "  \n",
    "  # Run sample ops\n",
    "  final_h, samples = session.run([sm.final_h_, sm.pred_samples_], \n",
    "        feed_dict={sm.input_w_: input_w, sm.initial_h_: initial_h, sm.dropout_keep_prob_: 1.0, sm.learning_rate_:0.1})\n",
    "  \n",
    "  #### END(YOUR CODE) ####\n",
    "  return final_h, samples[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-46-dddbebef1314>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-46-dddbebef1314>\"\u001b[1;36m, line \u001b[1;32m18\u001b[0m\n\u001b[1;33m    saver.restore(session, '.' trained_filename)\u001b[0m\n\u001b[1;37m                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Same as above, but as a batch\n",
    "reload(rnnsm)\n",
    "max_steps = 20\n",
    "num_samples = 10\n",
    "random_seed = 42\n",
    "\n",
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "  # Seed RNG for repeatability\n",
    "  tf.set_random_seed(random_seed)\n",
    "\n",
    "  with tf.variable_scope(\"model\", reuse=None):\n",
    "    sm = rnnsm.RNNSM(**model_params)\n",
    "    sm.BuildCoreGraph()\n",
    "    lsm.BuildSamplerGraph()\n",
    "\n",
    "  # Load the trained model\n",
    "  saver = tf.train.Saver()\n",
    "  saver.restore(session, '.' trained_filename)\n",
    "\n",
    "  # Make initial state for a batch with batch_size = num_samples\n",
    "  w = np.repeat([[vocab.START_ID]], num_samples, axis=0)\n",
    "  h = session.run(sm.initial_h_, {sm.input_w_: w})\n",
    "  # We'll take one step for each sequence on each iteration \n",
    "  for i in xrange(max_steps):\n",
    "    h, y = sample_step(sm, session, w[:,-1:], h)\n",
    "    w = np.hstack((w,y))\n",
    "\n",
    "  # Print generated sentences\n",
    "  for row in w:\n",
    "    for i, word_id in enumerate(row):\n",
    "      print vocab.id_to_word[word_id],\n",
    "      if (i != 0) and (word_id == vocab.START_ID):\n",
    "        break\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_seq(sm, session, seq, vocab):\n",
    "  \"\"\"Score a sequence of words. Returns total log-probability.\"\"\"\n",
    "  padded_ids = vocab.words_to_ids(utils.canonicalize_words([\"<s>\"] + seq, \n",
    "                                                           wordset=vocab.word_to_id))\n",
    "  w = np.reshape(padded_ids[:-1], [1,-1])\n",
    "  y = np.reshape(padded_ids[1:],  [1,-1])\n",
    "  h = session.run(sm.initial_h_, {sm.input_w_: w})\n",
    "  feed_dict = {sm.input_w_:w,\n",
    "               sm.target_y_:y,\n",
    "               sm.initial_h_:h,\n",
    "               sm.dropout_keep_prob_: 1.0}\n",
    "  # Return log(P(seq)) = -1*loss\n",
    "  return -1*session.run(sm.loss_, feed_dict)\n",
    "\n",
    "def load_and_score(inputs, sort=False):\n",
    "  \"\"\"Load the trained model and score the given words.\"\"\"\n",
    "  with tf.Graph().as_default(), tf.Session() as session:  \n",
    "    with tf.variable_scope(\"model\", reuse=None):\n",
    "      lm = rnnsm.RNNSM(**model_params)\n",
    "      lm.BuildCoreGraph()\n",
    "        \n",
    "    # Load the trained model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(session, './'+trained_filename)\n",
    "  \n",
    "    if isinstance(inputs[0], str) or isinstance(inputs[0], unicode):\n",
    "      inputs = [inputs]\n",
    "\n",
    "    # Actually run scoring\n",
    "    results = []\n",
    "    for words in inputs:\n",
    "      score = score_seq(lm, session, words, vocab)\n",
    "      results.append((score, words))\n",
    "    \n",
    "    # Sort if requested\n",
    "    if sort: results = sorted(results, reverse=True)\n",
    "    \n",
    "    # Print results\n",
    "    for score, words in results:\n",
    "      print \"\\\"%s\\\" : %.05f\" % (\" \".join(words), score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"once upon a time\" : -28.93479\n",
      "\"the quick brown fox jumps over the lazy dog\" : -63.21776\n"
     ]
    }
   ],
   "source": [
    "sents = [\"once upon a time\",\n",
    "         \"the quick brown fox jumps over the lazy dog\"]\n",
    "load_and_score([s.split() for s in sents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"the boy and the girl are\" : -36.40670\n",
      "\"the boy and the girl is\" : -34.56690\n",
      "\"the boys are\" : -16.81372\n",
      "\"the boys is\" : -16.17620\n",
      "\"there are many deer\" : -26.15632\n",
      "\"there are many deers\" : -19.46089\n"
     ]
    }
   ],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "sents = [\"the boy and the girl are\",\n",
    "         \"the boy and the girl is\",\n",
    "         \n",
    "         \"the boys are\", \n",
    "         \"the boys is\",\n",
    "         \n",
    "         \"there are many deer\", \n",
    "         \"there are many deers\"]\n",
    "load_and_score([s.split() for s in sents])\n",
    "\n",
    "#### END(YOUR CODE) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"In a good market, Apple's price falls\" : -39.03466\n",
      "\"In a good market, Apple's price rises\" : -41.51408\n",
      "\"In a good market, Apple's price stays\" : -37.77964\n"
     ]
    }
   ],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "\n",
    "sents = [\n",
    "         \"In a good market, Apple's price falls\",\n",
    "         \"In a good market, Apple's price rises\",\n",
    "    \"In a good market, Apple's price stays\"\n",
    "         ]\n",
    "load_and_score([s.split() for s in sents])\n",
    "\n",
    "\n",
    "#### END(YOUR CODE) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I have lots of green plastic square toys\" : -61.22992\n",
      "\"I have lots of green square plastic toys\" : -62.09601\n",
      "\"I have lots of plastic green square toys\" : -62.21913\n",
      "\"I have lots of square green plastic toys\" : -62.24586\n",
      "\"I have lots of plastic square green toys\" : -62.28750\n",
      "\"I have lots of square plastic green toys\" : -66.11003\n"
     ]
    }
   ],
   "source": [
    "prefix = \"I have lots of\".split()\n",
    "noun = \"toys\"\n",
    "adjectives = [\"square\", \"green\", \"plastic\"]\n",
    "inputs = []\n",
    "for adjs in itertools.permutations(adjectives):\n",
    "  words = prefix + list(adjs) + [noun]\n",
    "  inputs.append(words)\n",
    "    \n",
    "load_and_score(inputs, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I have lots of green plastic flat toys\" : -57.62775\n",
      "\"I have lots of green flat plastic toys\" : -59.28275\n",
      "\"I have lots of plastic green flat toys\" : -59.49638\n",
      "\"I have lots of plastic flat green toys\" : -60.39898\n",
      "\"I have lots of flat plastic green toys\" : -60.96680\n",
      "\"I have lots of flat green plastic toys\" : -61.51214\n"
     ]
    }
   ],
   "source": [
    "prefix = \"I have lots of Apple\".split()\n",
    "noun = \"toys\"\n",
    "adjectives = [\"stocks\", \"pies\", \"computers\"]\n",
    "inputs = []\n",
    "for adjs in itertools.permutations(adjectives):\n",
    "  words = prefix + list(adjs) + [noun]\n",
    "  inputs.append(words)\n",
    "    \n",
    "load_and_score(inputs, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I have lots of green plastic round toys\" : -59.50684\n",
      "\"I have lots of plastic green round toys\" : -61.64307\n",
      "\"I have lots of green round plastic toys\" : -61.85661\n",
      "\"I have lots of plastic round green toys\" : -62.10223\n",
      "\"I have lots of round green plastic toys\" : -62.98605\n",
      "\"I have lots of round plastic green toys\" : -63.16181\n"
     ]
    }
   ],
   "source": [
    "prefix = \"The future of Apple \".split()\n",
    "noun = \"toys\"\n",
    "adjectives = [\"round\", \"green\", \"plastic\"]\n",
    "inputs = []\n",
    "for adjs in itertools.permutations(adjectives):\n",
    "  words = prefix + list(adjs) + [noun]\n",
    "  inputs.append(words)\n",
    "    \n",
    "load_and_score(inputs, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I have lots of small plastic green toys\" : -55.65118\n",
      "\"I have lots of small green plastic toys\" : -56.18058\n",
      "\"I have lots of green plastic small toys\" : -58.51525\n",
      "\"I have lots of plastic small green toys\" : -58.71899\n",
      "\"I have lots of green small plastic toys\" : -59.45413\n",
      "\"I have lots of plastic green small toys\" : -60.29629\n"
     ]
    }
   ],
   "source": [
    "prefix = \"I have lots of\".split()\n",
    "noun = \"toys\"\n",
    "adjectives = [\"small\", \"green\", \"plastic\"]\n",
    "inputs = []\n",
    "for adjs in itertools.permutations(adjectives):\n",
    "  words = prefix + list(adjs) + [noun]\n",
    "  inputs.append(words)\n",
    "    \n",
    "load_and_score(inputs, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
